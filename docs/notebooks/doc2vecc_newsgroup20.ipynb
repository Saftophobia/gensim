{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(m):\n",
    "    \"\"\"Prints model name + workers and doc2vecc value\"\"\"\n",
    "    return str(m) + \" workers=\" + str(m.workers) +  \" doc2vecc=\" + str(m.doc2vecc)\n",
    "\n",
    "\n",
    "def average_vector(model, doc):\n",
    "    \"\"\"Constructs a document vector using the average of its words' vectors\"\"\"\n",
    "    doc_vector = np.zeros(model.vector_size)\n",
    "    size = 0\n",
    "    for word in doc:\n",
    "        if word in model.wv.vocab:\n",
    "            doc_vector += model.wv[word]\n",
    "            size += 1\n",
    "    if size > 0:\n",
    "        doc_vector /= size\n",
    "    return doc_vector\n",
    "\n",
    "\n",
    "def average_vector_batch(model, documents):\n",
    "    \"\"\"Batch document vector generation\"\"\"\n",
    "    return [average_vector(model, d) for d in documents]\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"identical vectors should yield similarity of 1.0\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def compare_vectors(docvecs_list, doc_x, doc_y, doc_z):\n",
    "    \"\"\"Returns True if doc_y is closer to doc_x than doc_z in the vector space.\"\"\"  \n",
    "    return cosine_similarity(docvecs_list[doc_x], docvecs_list[doc_y]) \\\n",
    "           > cosine_similarity(docvecs_list[doc_x], docvecs_list[doc_z])\n",
    "\n",
    "\n",
    "def compare_distances(docvecs_list, doc_x, doc_y, doc_z):\n",
    "    \"\"\" returns 1.0 if x and y are very close in the vector space, while x and z are very distant.\"\"\"\n",
    "    return 1.0 - sigmoid(\n",
    "        np.linalg.norm(docvecs_list[doc_x] - docvecs_list[doc_y]) -\n",
    "        np.linalg.norm(docvecs_list[doc_x] - docvecs_list[doc_z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroup = datasets.fetch_20newsgroups(subset=\"all\", shuffle=True, random_state=42, \n",
    "                                        remove=('header', 'footer', 'quotes'))\n",
    "\n",
    "processed_docs = [gensim.utils.simple_preprocess(x) for x in newsgroup['data']]\n",
    "\n",
    "X_train, X_test, _, y_test = model_selection.train_test_split(processed_docs, newsgroup['target'], \n",
    "                                                              random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset of triplets: \n",
    "# - Document A, \n",
    "# - Document B sampled from the same category as A's\n",
    "# - document C randomly sampled from the dataset with category different than A's\n",
    "\n",
    "df = pd.DataFrame(y_test, columns=['target'])\n",
    "df['index'] = df.index\n",
    "\n",
    "np.random.seed(131)\n",
    "\n",
    "df_sample = df.sample(frac=0.20)\n",
    "\n",
    "df_positive = pd\\\n",
    "    .merge(df_sample, df_sample, left_on='target', right_on=df_sample['target'])\\\n",
    "    .drop(['target_x', 'target_y'], axis=1)\n",
    "\n",
    "# remove same documents\n",
    "df_positive = df_positive[df_positive['index_x'] != df_positive['index_y']]\n",
    "\n",
    "# Add the randomly added documents\n",
    "df_negative = df.sample(len(df_positive), replace=True)\n",
    "df_negative.columns = ['target_z', 'index_z']\n",
    "\n",
    "df_positive['target_z'] = df_negative['target_z'].values\n",
    "df_positive['index_z']  = df_negative['index_z'].values\n",
    "\n",
    "# remove Documents C with the same category as Document A \n",
    "df_positive_negative = df_positive[df_positive['target'] != df_positive['target_z']].drop(['target', 'target_z'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models training \n",
    "\n",
    "models = []\n",
    "for i in np.arange(0, 1.2, 0.2):\n",
    "    model = gensim.models.word2vec.Word2Vec(X_train[1:5], size=100, alpha=0.025, window=5, min_count=3, \n",
    "                                                 sample=1e-3, seed=42, workers=6, min_alpha=0.0001, \n",
    "                                                 sg=1, hs=0, negative=5, ns_exponent=0.75, cbow_mean=0, \n",
    "                                                 iter=30, doc2vecc=i)\n",
    "    model.wv.save(\"~/trained_models/doc2vec_%f.wv\" % i)\n",
    "    models.append((print_model(model), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate document vectors for every model\n",
    "models_average_vector = [(k, average_vector_batch(model, X_test)) for k, model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction accuracy and average distance         \n",
    "for k, vecs in models_average_vector:\n",
    "    true_positives = df_positive_negative.apply(lambda x: compare_vectors(vecs, *x), axis=1).sum()\n",
    "    avg_distance   = df_positive_negative.apply(lambda x: compare_distances(vecs, *x), axis=1).mean()\n",
    "    \n",
    "    print('-'*75)\n",
    "    print(\"%s classified:\\t\\t %i correctly,\\t %f%%\" % (k,true_positives, true_positives/len(df_positive_negative) * 100))\n",
    "    print(\"%s average distance: \\t %f\" % (k, avg_distance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.0 classified:          52498 correctly,        70.450093%\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.0 average distance:    0.527342\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.2 classified:          57388 correctly,        77.012265%\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.2 average distance:    0.553244\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.4 classified:          57383 correctly,        77.005556%\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.4 average distance:    0.554434\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.6 classified:          57354 correctly,        76.966639%\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.6 average distance:    0.554916\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.8 classified:          57141 correctly,        76.680802%\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=0.8 average distance:    0.554535\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=1.0 classified:          56961 correctly,        76.439250%\n",
    "\n",
    "Word2Vec(vocab=37064, size=100, alpha=0.025) workers=6 doc2vecc=1.0 average distance:    0.554650\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

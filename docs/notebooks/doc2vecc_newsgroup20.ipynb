{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection\n",
    "\n",
    "import gensim\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(type, workers, doc2vecc):\n",
    "    \"\"\"Prints model name + workers and doc2vecc value\"\"\"\n",
    "    return type + \"workers=\" + str(workers) +  \" doc2vecc=\" + str(doc2vecc)\n",
    "\n",
    "\n",
    "def average_vector(model, doc):\n",
    "    \"\"\"Constructs a document vector using the average of its words' vectors\"\"\"\n",
    "    doc_vector = np.zeros(model.vector_size)\n",
    "    size = 0\n",
    "    for word in doc:\n",
    "        if word in model.wv.vocab:\n",
    "            doc_vector += model.wv[word]\n",
    "            size += 1\n",
    "    if size > 0:\n",
    "        doc_vector /= size\n",
    "    return doc_vector\n",
    "\n",
    "\n",
    "def average_vector_batch(model, documents):\n",
    "    \"\"\"Batch document vector generation\"\"\"\n",
    "    return [average_vector(model, d) for d in documents]\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"identical vectors should yield similarity of 1.0\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def compare_vectors(docvecs_list, doc_x, doc_y, doc_z):\n",
    "    \"\"\"Returns True if doc_y is closer to doc_x than doc_z in the vector space.\"\"\"  \n",
    "    return cosine_similarity(docvecs_list[doc_x], docvecs_list[doc_y]) \\\n",
    "           > cosine_similarity(docvecs_list[doc_x], docvecs_list[doc_z])\n",
    "\n",
    "\n",
    "def compare_distances(docvecs_list, doc_x, doc_y, doc_z):\n",
    "    \"\"\" returns 1.0 if x and y are very close in the vector space, while x and z are very distant.\"\"\"\n",
    "    return 1.0 - sigmoid(\n",
    "        np.linalg.norm(docvecs_list[doc_x] - docvecs_list[doc_y]) -\n",
    "        np.linalg.norm(docvecs_list[doc_x] - docvecs_list[doc_z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroup = datasets.fetch_20newsgroups(subset=\"all\", shuffle=True, random_state=42, \n",
    "                                        remove=('header', 'footer', 'quotes'))\n",
    "\n",
    "processed_docs = [gensim.utils.simple_preprocess(x) for x in newsgroup['data']]\n",
    "\n",
    "X_train, X_test, _, y_test = model_selection.train_test_split(processed_docs, newsgroup['target'], \n",
    "                                                              random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset of triplets: \n",
    "# - Document A, \n",
    "# - Document B sampled from the same category as A's\n",
    "# - document C randomly sampled from the dataset with category different than A's\n",
    "\n",
    "df = pd.DataFrame(y_test, columns=['target'])\n",
    "df['index'] = df.index\n",
    "\n",
    "np.random.seed(131)\n",
    "\n",
    "df_sample = df.sample(frac=0.20)\n",
    "\n",
    "df_positive = pd\\\n",
    "    .merge(df_sample, df_sample, left_on='target', right_on=df_sample['target'])\\\n",
    "    .drop(['target_x', 'target_y'], axis=1)\n",
    "\n",
    "# remove same documents\n",
    "df_positive = df_positive[df_positive['index_x'] != df_positive['index_y']]\n",
    "\n",
    "# Add the randomly added documents\n",
    "df_negative = df.sample(len(df_positive), replace=True)\n",
    "df_negative.columns = ['target_z', 'index_z']\n",
    "\n",
    "df_positive['target_z'] = df_negative['target_z'].values\n",
    "df_positive['index_z']  = df_negative['index_z'].values\n",
    "\n",
    "# remove Documents C with the same category as Document A \n",
    "df_positive_negative = df_positive[df_positive['target'] != df_positive['target_z']].drop(['target', 'target_z'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models training - gensim\n",
    "models = []\n",
    "for i in np.arange(0, 1.2, 0.2):\n",
    "    model = gensim.models.word2vec.Word2Vec(X_train[1:5], size=100, alpha=0.025, window=5, min_count=3, \n",
    "                                            sample=1e-3, seed=42, workers=6, min_alpha=0.0001, \n",
    "                                            sg=1, hs=0, negative=5, ns_exponent=0.75, cbow_mean=0, \n",
    "                                            iter=30, doc2vecc=i)\n",
    "    model.wv.save(\"~/trained_models/doc2vec_%f.wv\" % i)\n",
    "    models.append((print_model(\"Gensim:\", 6, i), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:19,637 : INFO : loading projection weights from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:23,324 : INFO : loaded (37065, 100) matrix from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:23,325 : INFO : loading projection weights from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:27,027 : INFO : loaded (37065, 100) matrix from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:27,028 : INFO : loading projection weights from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:30,494 : INFO : loaded (37065, 100) matrix from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:30,494 : INFO : loading projection weights from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:33,967 : INFO : loaded (37065, 100) matrix from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_0.8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:33,968 : INFO : loading projection weights from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_1.0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 15:49:37,864 : INFO : loaded (37065, 100) matrix from /Users/ahmed.elsafty/Downloads/trained_models/wordvectors_1.0.txt\n"
     ]
    }
   ],
   "source": [
    "# Models training - C code from doc2vecc\n",
    "\n",
    "# for i in `seq 0.2 0.2 1.0`;\n",
    "# do\n",
    "#     echo doc2vecc_$i\n",
    "#     time ./doc2vecc   -train ../../X_train.txt -word wordvectors_$i.txt -cbow 0 \n",
    "#                       -size 100 -window 5 -negative 5 -hs 0 -sample 0.001 -threads 6 -binary 0 -iter 30 -min-count 3 \\\n",
    "#                       -sentence-sample $i -alpha 0.025 -save-vocab tmp.vocab -test alldata.txt \n",
    "#                       -output docvectors.txt\n",
    "# done\n",
    "\n",
    "for i in np.arange(0.2, 1.2, 0.2):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(\"wordvectors_%s.txt\" % i, binary=False)\n",
    "    models.append((print_model(\"C:\", 6, i), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmed.elsafty/Downloads/venv/lib/python3.5/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  # This is added back by InteractiveShellApp.init_path()\n/Users/ahmed.elsafty/Downloads/venv/lib/python3.5/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# generate document vectors for every model\n",
    "models_average_vector = [(k, average_vector_batch(model, X_test)) for k, model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nGensim: workers=6 doc2vecc=0.0 classified:\t\t 52498 correctly,\t 70.450093%\nGensim: workers=6 doc2vecc=0.0 average distance: \t 0.527342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nGensim: workers=6 doc2vecc=0.2 classified:\t\t 57388 correctly,\t 77.012265%\nGensim: workers=6 doc2vecc=0.2 average distance: \t 0.553244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nGensim: workers=6 doc2vecc=0.4 classified:\t\t 57383 correctly,\t 77.005556%\nGensim: workers=6 doc2vecc=0.4 average distance: \t 0.554434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nGensim: workers=6 doc2vecc=0.6 classified:\t\t 57354 correctly,\t 76.966639%\nGensim: workers=6 doc2vecc=0.6 average distance: \t 0.554916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nGensim: workers=6 doc2vecc=0.8 classified:\t\t 57141 correctly,\t 76.680802%\nGensim: workers=6 doc2vecc=0.8 average distance: \t 0.554535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nGensim: workers=6 doc2vecc=1.0 classified:\t\t 56961 correctly,\t 76.439250%\nGensim: workers=6 doc2vecc=1.0 average distance: \t 0.554650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nC:workers=6 doc2vecc=0.2 classified:\t\t 49652 correctly,\t 66.630881%\nC:workers=6 doc2vecc=0.2 average distance: \t 0.632914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nC:workers=6 doc2vecc=0.4 classified:\t\t 44381 correctly,\t 59.557422%\nC:workers=6 doc2vecc=0.4 average distance: \t 0.572672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nC:workers=6 doc2vecc=0.6 classified:\t\t 43069 correctly,\t 57.796774%\nC:workers=6 doc2vecc=0.6 average distance: \t 0.561308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nC:workers=6 doc2vecc=0.8 classified:\t\t 42606 correctly,\t 57.175448%\nC:workers=6 doc2vecc=0.8 average distance: \t 0.557564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmed.elsafty/Downloads/venv/lib/python3.5/site-packages/ipykernel_launcher.py:30: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\nC:workers=6 doc2vecc=1.0 classified:\t\t 41866 correctly,\t 56.182399%\nC:workers=6 doc2vecc=1.0 average distance: \t 0.557967\n"
     ]
    }
   ],
   "source": [
    "# Prediction accuracy and average distance         \n",
    "for k, vecs in models_average_vector:\n",
    "    true_positives = df_positive_negative.apply(lambda x: compare_vectors(vecs, *x), axis=1).sum()\n",
    "    avg_distance   = df_positive_negative.apply(lambda x: compare_distances(vecs, *x), axis=1).mean()\n",
    "    \n",
    "    print('-'*75)\n",
    "    print(\"%s classified:\\t\\t %i correctly,\\t %f%%\" % (k,true_positives, true_positives/len(df_positive_negative) * 100))\n",
    "    print(\"%s average distance: \\t %f\" % (k, avg_distance))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
